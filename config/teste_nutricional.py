#!/usr/bin/env python3
"""
Script de teste para coleta de dados nutricionais de produtos individuais
URL de teste: https://www.integralmedica.com.br/whey-protein-concentrado-pouch-900g/p
"""

import requests
from bs4 import BeautifulSoup, Tag
import re
import json
from typing import Dict, Optional

class NutritionalDataExtractor:
    """
    Extrator de dados nutricionais de produtos individuais
    """
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'pt-BR,pt;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        })
        
        # Campos que queremos extrair
        self.target_fields = {
            'URL': '',
            'NOME_PRODUTO': '',
            'POR√á√ÉO (g)': '0',
            'CALORIAS (kcal)': '0',
            'CARBOIDRATOS (g)': '0',
            'PROTE√çNAS (g)': '0',
            'GORDURAS_TOTAIS (g)': '0',
            'GORDURAS_SATURADAS (g)': '0',
            'FIBRAS (g)': '0',
            'A√á√öCARES (g)': '0',
            'S√ìDIO (mg)': '0'
        }
    
    def get_page_content(self, url: str) -> Optional[BeautifulSoup]:
        """
        Obt√©m conte√∫do da p√°gina
        """
        try:
            print(f"üîç Acessando: {url}")
            response = self.session.get(url, timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            print(f"‚úÖ P√°gina carregada com sucesso")
            return soup
            
        except requests.RequestException as e:
            print(f"‚ùå Erro ao acessar p√°gina: {e}")
            return None
    
    def extract_product_name(self, soup: BeautifulSoup) -> str:
        """
        Extrai o nome do produto
        """
        print("üîç Procurando nome do produto...")
        
        # Estrat√©gias para encontrar o nome do produto
        name_selectors = [
            'h1',  # T√≠tulo principal
            'h2',  # Subt√≠tulo
            '.product-name',
            '.product-title',
            '.nome-produto',
            '[class*="product"][class*="name"]',
            '[class*="product"][class*="title"]',
            'h1[class*="product"]',
            'h2[class*="product"]'
        ]
        
        for selector in name_selectors:
            try:
                element = soup.select_one(selector)
                if element:
                    name = element.get_text(strip=True)
                    if name and len(name) > 3:  # Nome v√°lido
                        print(f"‚úÖ Nome encontrado: {name}")
                        return name
            except Exception as e:
                print(f"‚ö†Ô∏è  Erro no seletor {selector}: {e}")
                continue
        
        # Se n√£o encontrou pelos seletores, procurar no t√≠tulo da p√°gina
        title_tag = soup.find('title')
        if title_tag:
            title = title_tag.get_text(strip=True)
            # Remover texto comum do t√≠tulo
            title = re.sub(r'\s*\|\s*.*$', '', title)  # Remove "| Integral M√©dica"
            if title and len(title) > 3:
                print(f"‚úÖ Nome encontrado no t√≠tulo: {title}")
                return title
        
        print("‚ùå Nome do produto n√£o encontrado")
        return "Produto n√£o identificado"
    
    def extract_nutritional_data(self, soup: BeautifulSoup) -> Dict[str, str]:
        """
        Extrai dados nutricionais da tabela
        """
        print("üîç Procurando tabela nutricional...")
        
        # Procurar se√ß√£o da tabela nutricional
        nutrition_section = self.find_nutrition_section(soup)
        
        if not nutrition_section:
            print("‚ùå Se√ß√£o nutricional n√£o encontrada")
            return {}
        
        print("‚úÖ Se√ß√£o nutricional encontrada")
        
        # Extrair dados
        nutrition_data = {}
        
        # Procurar por tabela HTML
        table = nutrition_section.find('table')
        if table and isinstance(table, Tag):
            print("‚úÖ Tabela HTML encontrada")
            nutrition_data = self.parse_html_table(table)
        else:
            print("‚ö†Ô∏è  Tabela HTML n√£o encontrada, tentando parsing de texto")
            nutrition_data = self.parse_nutrition_text(nutrition_section)
        
        return nutrition_data
    
    def find_nutrition_section(self, soup: BeautifulSoup) -> Optional[BeautifulSoup]:
        """
        Encontra a se√ß√£o da tabela nutricional
        """
        # Procurar por texto indicativo
        text_indicators = [
            'tabela nutricional',
            'informa√ß√£o nutricional',
            'nutrition',
            'nutricional'
        ]
        
        for indicator in text_indicators:
            # Procurar por elementos que contenham o texto
            elements = soup.find_all(string=re.compile(indicator, re.I))
            for element in elements:
                # Subir na √°rvore para encontrar o container
                parent = element.parent
                for _ in range(8):  # At√© 8 n√≠veis acima
                    if parent:
                        # Verificar se √© uma se√ß√£o relevante
                        if parent.name in ['div', 'section', 'article', 'table']:
                            # Verificar se cont√©m dados nutricionais
                            text_content = parent.get_text().lower()
                            if any(term in text_content for term in ['calorias', 'prote√≠nas', 'carboidratos', 'kcal']):
                                return parent
                        parent = parent.parent
                    else:
                        break
        
        return None
    
    def parse_html_table(self, table: Tag) -> Dict[str, str]:
        """
        Faz parsing de uma tabela HTML
        """
        data = {}
        
        # Mapeamento de termos para nossos campos (ordem importa - mais espec√≠fico primeiro)
        field_mapping = {
            'por√ß√£o': 'POR√á√ÉO (g)',
            'valor energ√©tico': 'CALORIAS (kcal)',
            'calorias': 'CALORIAS (kcal)',
            'carboidratos': 'CARBOIDRATOS (g)',
            'prote√≠nas': 'PROTE√çNAS (g)',
            'gorduras totais': 'GORDURAS_TOTAIS (g)',
            'gorduras saturadas': 'GORDURAS_SATURADAS (g)',
            'fibras alimentares': 'FIBRAS (g)',
            'fibras': 'FIBRAS (g)',
            'a√ß√∫cares totais': 'A√á√öCARES (g)',  # Priorizar "a√ß√∫cares totais" sobre "a√ß√∫cares"
            's√≥dio': 'S√ìDIO (mg)'
        }
        
        # Procurar por linhas da tabela
        rows = table.find_all('tr')
        
        for row in rows:
            cells = row.find_all(['td', 'th'])
            if len(cells) >= 2:
                # Primeira coluna: nome do nutriente
                label = cells[0].get_text(strip=True).lower()
                # Segunda coluna: valor
                value = cells[1].get_text(strip=True)
                
                # Verificar se encontramos um campo que queremos
                for search_term, field_name in field_mapping.items():
                    if search_term in label:
                        # Extrair n√∫mero
                        number = self.extract_number(value)
                        if number:
                            data[field_name] = number
                            print(f"‚úÖ Encontrado {field_name}: {number}")
                            break
        
        return data
    
    def parse_nutrition_text(self, section: BeautifulSoup) -> Dict[str, str]:
        """
        Faz parsing do texto da se√ß√£o nutricional
        """
        data = {}
        text = section.get_text()
        
        # Padr√µes para encontrar dados
        patterns = {
            'POR√á√ÉO (g)': [
                r'por√ß√£o[:\s]*(\d+(?:[,\.]\d+)?)\s*g',
                r'(\d+(?:[,\.]\d+)?)\s*g.*(?:dosador|por√ß√£o)'
            ],
            'CALORIAS (kcal)': [
                r'(?:valor energ√©tico|calorias)[:\s]*(\d+(?:[,\.]\d+)?)',
                r'(\d+(?:[,\.]\d+)?)\s*kcal'
            ],
            'CARBOIDRATOS (g)': [
                r'carboidratos[:\s]*(\d+(?:[,\.]\d+)?)',
            ],
            'PROTE√çNAS (g)': [
                r'prote√≠nas[:\s]*(\d+(?:[,\.]\d+)?)',
            ],
            'GORDURAS_TOTAIS (g)': [
                r'gorduras totais[:\s]*(\d+(?:[,\.]\d+)?)',
            ],
            'GORDURAS_SATURADAS (g)': [
                r'gorduras saturadas[:\s]*(\d+(?:[,\.]\d+)?)',
            ],
            'FIBRAS (g)': [
                r'fibras[:\s]*(\d+(?:[,\.]\d+)?)',
            ],
            'A√á√öCARES (g)': [
                r'a√ß√∫cares[:\s]*(\d+(?:[,\.]\d+)?)',
            ],
            'S√ìDIO (mg)': [
                r's√≥dio[:\s]*(\d+(?:[,\.]\d+)?)',
            ]
        }
        
        for field_name, pattern_list in patterns.items():
            for pattern in pattern_list:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    value = match.group(1).replace(',', '.')
                    data[field_name] = value
                    print(f"‚úÖ Encontrado {field_name}: {value}")
                    break
        
        return data
    
    def extract_number(self, text: str) -> Optional[str]:
        """
        Extrai n√∫mero de um texto
        """
        # Procurar por n√∫mero (pode ter v√≠rgula ou ponto decimal)
        match = re.search(r'(\d+(?:[,\.]\d+)?)', text)
        if match:
            return match.group(1).replace(',', '.')
        return None
    
    def extract_all_data(self, url: str) -> Dict[str, str]:
        """
        Extrai todos os dados de um produto
        """
        # Inicializar dados
        product_data = self.target_fields.copy()
        product_data['URL'] = url
        
        # Obter conte√∫do da p√°gina
        soup = self.get_page_content(url)
        if not soup:
            return product_data
        
        # Extrair nome do produto
        product_name = self.extract_product_name(soup)
        product_data['NOME_PRODUTO'] = product_name
        
        # Extrair dados nutricionais
        nutrition_data = self.extract_nutritional_data(soup)
        
        # Atualizar dados com os valores encontrados
        for field, value in nutrition_data.items():
            if field in product_data:
                product_data[field] = value
        
        return product_data
    
    def print_results(self, data: Dict[str, str]):
        """
        Imprime resultados formatados
        """
        print("\n" + "="*80)
        print("üìä DADOS COLETADOS")
        print("="*80)
        
        for field, value in data.items():
            if field == 'URL':
                print(f"üîó {field}: {value}")
            elif field == 'NOME_PRODUTO':
                print(f"üì¶ {field}: {value}")
            else:
                print(f"üìã {field}: {value}")
        
        print("="*80)
        
        # Estat√≠sticas
        non_zero_fields = sum(1 for field, value in data.items() 
                             if field not in ['URL', 'NOME_PRODUTO'] and value != '0')
        total_nutrition_fields = len(data) - 2  # Excluir URL e NOME_PRODUTO
        
        print(f"üìà Campos nutricionais encontrados: {non_zero_fields}/{total_nutrition_fields}")
        print(f"üéØ Taxa de sucesso: {(non_zero_fields/total_nutrition_fields)*100:.1f}%")
        print("="*80)

def main():
    """
    Fun√ß√£o principal para teste
    """
    # URL de teste
    test_url = "https://www.integralmedica.com.br/whey-protein-concentrado-pouch-900g/p"
    
    print("üöÄ TESTE DE COLETA DE DADOS NUTRICIONAIS")
    print("="*80)
    print(f"üìã URL de teste: {test_url}")
    print("="*80)
    
    # Criar extrator
    extractor = NutritionalDataExtractor()
    
    # Extrair dados
    product_data = extractor.extract_all_data(test_url)
    
    # Mostrar resultados
    extractor.print_results(product_data)
    
    # Salvar em JSON para an√°lise
    with open('teste_produto.json', 'w', encoding='utf-8') as f:
        json.dump(product_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nüíæ Dados salvos em: teste_produto.json")

if __name__ == "__main__":
    main() 